{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# Python Project for Data Engineering\n",
    "## A Simple ETL Project:\n",
    "\n",
    "This notebook have the detail implementation of the project that is compulosry for the **IBM Data Engineering Professional Certification**.\n"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Ycu78nhiBX1YcvhgckPnyf",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "*   Read CSV and JSON file types.\n",
    "*   Extract data from the above file types.\n",
    "*   Transform data.\n",
    "*   Save the **transformed data in a ready-to-load format** which data engineers can use to load into an RDBMS."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"2mvp58lCv0oJ5U0fL1bGCv",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "<img src=\"Pics\/Simple ETL Project Flow.drawio.png\">"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"20QWEkfY7HUH0cnmstvYHp",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**Import the Important Libraries**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"LgKgT7qW3vNBg7hI6qZrXn",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"KDSvPvZxyBjOtbmeO218no",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **EXAMPLE:** 1"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"4uCf7Lx0nCbaNhDQnc3Xbd",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**Downloading the Source Files which are stored in S3 bucket.**\n",
    "\n",
    "- We will use **Wget** which is a **networking command-line tool** that lets you download files and interact with REST APIs. \n",
    "  \n",
    "- It supports the HTTP , HTTPS , FTP , and FTPS internet protocols. Wget can deal with unstable and slow network connections. In the event of a download failure, Wget keeps trying until the entire file has been retrieved."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"041p151J6Irli0wlnOPP48",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!wget https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork\/labs\/module%206\/Lab%20-%20Extract%20Transform%20Load\/data\/source.zip"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "--2022-09-07 14:50:21--  https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork\/labs\/module%206\/Lab%20-%20Extract%20Transform%20Load\/data\/source.zip\r\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\r\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2707 (2.6K) [application\/zip]\r\n",
      "Saving to: ‘source.zip’\r\n",
      "\r\n",
      "\rsource.zip            0%[                    ]       0  --.-KB\/s               \rsource.zip          100%[===================>]   2.64K  --.-KB\/s    in 0s      \r\n",
      "\r\n",
      "2022-09-07 14:50:22 (822 MB\/s) - ‘source.zip’ saved [2707\/2707]\r\n",
      "\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"x6gfVSVdxzhE8RiQPiM8dM",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "In DataLore Menu bar, you will see Attach Data Option. Click on it and you will see the downloaded Zip file."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"oiHFXAmtEIM5ZULBpN5NDW",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**Unzip Files**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"ULEegcuSzqQUUl6ClYcstA",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Now unzip the source.zip file\n",
    "!unzip source.zip"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Archive:  source.zip\r\n",
      "  inflating: source3.json            \r\n",
      "  inflating: source1.csv             \r\n",
      "  inflating: source2.csv             \r\n",
      "  inflating: source3.csv             \r\n",
      "  inflating: source1.json            \r\n",
      "  inflating: source2.json            \r\n",
      "  inflating: source1.xml             \r\n",
      "  inflating: source2.xml             \r\n",
      "  inflating: source3.xml             \r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"a2fnNzYkt3g58VlpPuJXqD",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "<img src=\"Pics\/Screenshot 2022-09-07 at 9.17.59 AM.png\">"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"0SuN24tmTnvFQBG3gTDH4t",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "You can see different files with different formats."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"XVQ1Xs7mDMh91Hzoyw4vqY",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**Set Paths:**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"nojtCLsjif298A0F48ZG8p",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "tmpfile = \"temp.tmp\"\n",
    "logfile = \"logfile.txt\"\n",
    "targetfile = \"transformed_data.csv\""
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"mDLZWAkUFibnIyd7OSnsAH",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Extract:**\n",
    "\n",
    "Lets move to our first step which is Extract. In this Step, we will extract data from each file into one file."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"h8WBmvhrHaW08afv2e6ZIM",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# CSV Extract Function\n",
    "def extracting_from_csv(file):\n",
    "    dataframe = pd.read_csv(file)\n",
    "    return dataframe\n",
    "\n",
    "# JSON Extract Function\n",
    "def extracting_from_json(file):\n",
    "    dataframe = pd.read_json(file, lines=True) # Read the file as a json object per line.\n",
    "    return dataframe\n",
    "\n",
    "# XML Extract Function\n",
    "def extracting_from_xml(file):\n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    for i in root:\n",
    "        name = i.find(\"name\").text\n",
    "        height = i.find(\"height\").text\n",
    "        weight = i.find(\"weight\").text\n",
    "        dataframe = dataframe.append({\"name\": name, \"height\": height, \"weight\": weight}, ignore_index=True)\n",
    "        return dataframe"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"ggzfpDMd1olWK1aP9fdE5M",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**Extract Function:**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"9dk2mcb4dyJrlf6DooDCbN",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def extract():\n",
    "    # First Create an Empty Df\n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight'])\n",
    "\n",
    "    # Process all csv files: Use Glob\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = extracted_data.append(extracting_from_csv(csvfile), ignore_index=True)\n",
    "        # When ignore_index=True, then the order of each row would be the same as the order \n",
    "        # the row was appended to the data frame.\n",
    "\n",
    "    # Process all json files\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = extracted_data.append(extracting_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    # Process all xml files\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = extracted_data.append(extracting_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"cD3X5KA5I27C1r4BgLRUjT",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Transform:**\n",
    "\n",
    "In this case, th transform function does the following tasks.\n",
    "\n",
    "1.  Convert height which is in inches to millimeter\n",
    "2.  Convert weight which is in pounds to kilograms"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Glcda7FYgrgwaTm9v3Oz8w",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def transformation(data):\n",
    "    # Convert height from inches to millimeter\n",
    "    data.height = data.height.astype(float)\n",
    "    data['height'] = round(data.height * 0.0254, 2)\n",
    "\n",
    "    # Converting weight from pounds to kilogram\n",
    "    data.weight = data.weight.astype(float)\n",
    "    data['weight'] = round(data.weight * 0.45359237, 2)\n",
    "\n",
    "    return data"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"eeCXWsRrk7yRnJb7cPsPO9",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Loading Data:**\n",
    "\n",
    "As Extraction and Transformation are done successfully, now we have to load the data into csv file."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"R4sEsHRvhu1XtgypicmN8J",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def load(targetfile, data_to_load):\n",
    "    data_to_load.to_csv(targetfile)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"PVAeRZp0T2ap3JiUKrIc6c",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Logging:**\n",
    "\n",
    "- I have used logging by importing the logging package\n",
    "in python. \n",
    "\n",
    "- We can access logging package functionalities by using a logger. \n",
    "- Logger allows us to set the format in which the logs will generate."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"oTOa7emP9supfyQYGITZV6",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # Get the current time\n",
    "    timestamp  = now.strftime(timestamp_format)\n",
    "    with open(\"logfile.txt\", 'a') as file:\n",
    "        file.write(timestamp + ',' + message + '\\n')"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"VQjCwwbZpPr5zsBk7lvsv6",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Running ETL Process:**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"AGpxHDj9j0WGMnSi0kPF68",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "log(\"ETL Job Started\")"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"7vtTKs7AKsh0vKDZxrPwkv",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Extracting Data\n",
    "\n",
    "log(\"Extract Phase Started:\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract Phase Ended:\")\n",
    "extracted_data"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>name<\/th>\n",
       "      <th>height<\/th>\n",
       "      <th>weight<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>alex<\/td>\n",
       "      <td>65.78<\/td>\n",
       "      <td>112.99<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>ajay<\/td>\n",
       "      <td>71.52<\/td>\n",
       "      <td>136.49<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>alice<\/td>\n",
       "      <td>69.4<\/td>\n",
       "      <td>153.03<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>ravi<\/td>\n",
       "      <td>68.22<\/td>\n",
       "      <td>142.34<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>joe<\/td>\n",
       "      <td>67.79<\/td>\n",
       "      <td>144.3<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>5<\/th>\n",
       "      <td>alex<\/td>\n",
       "      <td>65.78<\/td>\n",
       "      <td>112.99<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>6<\/th>\n",
       "      <td>ajay<\/td>\n",
       "      <td>71.52<\/td>\n",
       "      <td>136.49<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>7<\/th>\n",
       "      <td>alice<\/td>\n",
       "      <td>69.4<\/td>\n",
       "      <td>153.03<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>8<\/th>\n",
       "      <td>ravi<\/td>\n",
       "      <td>68.22<\/td>\n",
       "      <td>142.34<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>9<\/th>\n",
       "      <td>joe<\/td>\n",
       "      <td>67.79<\/td>\n",
       "      <td>144.3<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>10<\/th>\n",
       "      <td>alex<\/td>\n",
       "      <td>65.78<\/td>\n",
       "      <td>112.99<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>11<\/th>\n",
       "      <td>ajay<\/td>\n",
       "      <td>71.52<\/td>\n",
       "      <td>136.49<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>12<\/th>\n",
       "      <td>alice<\/td>\n",
       "      <td>69.4<\/td>\n",
       "      <td>153.03<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>13<\/th>\n",
       "      <td>ravi<\/td>\n",
       "      <td>68.22<\/td>\n",
       "      <td>142.34<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>14<\/th>\n",
       "      <td>joe<\/td>\n",
       "      <td>67.79<\/td>\n",
       "      <td>144.3<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>15<\/th>\n",
       "      <td>jack<\/td>\n",
       "      <td>68.7<\/td>\n",
       "      <td>123.3<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>16<\/th>\n",
       "      <td>tom<\/td>\n",
       "      <td>69.8<\/td>\n",
       "      <td>141.49<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>17<\/th>\n",
       "      <td>tracy<\/td>\n",
       "      <td>70.01<\/td>\n",
       "      <td>136.46<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>18<\/th>\n",
       "      <td>john<\/td>\n",
       "      <td>67.9<\/td>\n",
       "      <td>112.37<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>19<\/th>\n",
       "      <td>jack<\/td>\n",
       "      <td>68.7<\/td>\n",
       "      <td>123.3<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>20<\/th>\n",
       "      <td>tom<\/td>\n",
       "      <td>69.8<\/td>\n",
       "      <td>141.49<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>21<\/th>\n",
       "      <td>tracy<\/td>\n",
       "      <td>70.01<\/td>\n",
       "      <td>136.46<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>22<\/th>\n",
       "      <td>john<\/td>\n",
       "      <td>67.9<\/td>\n",
       "      <td>112.37<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>23<\/th>\n",
       "      <td>jack<\/td>\n",
       "      <td>68.7<\/td>\n",
       "      <td>123.3<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>24<\/th>\n",
       "      <td>tom<\/td>\n",
       "      <td>69.8<\/td>\n",
       "      <td>141.49<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>25<\/th>\n",
       "      <td>tracy<\/td>\n",
       "      <td>70.01<\/td>\n",
       "      <td>136.46<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>26<\/th>\n",
       "      <td>john<\/td>\n",
       "      <td>67.9<\/td>\n",
       "      <td>112.37<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>27<\/th>\n",
       "      <td>simon<\/td>\n",
       "      <td>67.90<\/td>\n",
       "      <td>112.37<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>28<\/th>\n",
       "      <td>simon<\/td>\n",
       "      <td>67.90<\/td>\n",
       "      <td>112.37<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>29<\/th>\n",
       "      <td>simon<\/td>\n",
       "      <td>67.90<\/td>\n",
       "      <td>112.37<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"CDnZuaFPwdBRsQxNgoHQd3",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Transformation Data\n",
    "\n",
    "log(\"Transformation Phase Started:\")\n",
    "transformed_data = transformation(extracted_data)\n",
    "log(\"Transformation Phase Ended:\")\n",
    "transformed_data"
   ],
   "execution_count":null,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>name<\/th>\n",
       "      <th>height<\/th>\n",
       "      <th>weight<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>alex<\/td>\n",
       "      <td>1.67<\/td>\n",
       "      <td>51.25<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>ajay<\/td>\n",
       "      <td>1.82<\/td>\n",
       "      <td>61.91<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>alice<\/td>\n",
       "      <td>1.76<\/td>\n",
       "      <td>69.41<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>ravi<\/td>\n",
       "      <td>1.73<\/td>\n",
       "      <td>64.56<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>joe<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>65.45<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>5<\/th>\n",
       "      <td>alex<\/td>\n",
       "      <td>1.67<\/td>\n",
       "      <td>51.25<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>6<\/th>\n",
       "      <td>ajay<\/td>\n",
       "      <td>1.82<\/td>\n",
       "      <td>61.91<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>7<\/th>\n",
       "      <td>alice<\/td>\n",
       "      <td>1.76<\/td>\n",
       "      <td>69.41<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>8<\/th>\n",
       "      <td>ravi<\/td>\n",
       "      <td>1.73<\/td>\n",
       "      <td>64.56<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>9<\/th>\n",
       "      <td>joe<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>65.45<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>10<\/th>\n",
       "      <td>alex<\/td>\n",
       "      <td>1.67<\/td>\n",
       "      <td>51.25<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>11<\/th>\n",
       "      <td>ajay<\/td>\n",
       "      <td>1.82<\/td>\n",
       "      <td>61.91<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>12<\/th>\n",
       "      <td>alice<\/td>\n",
       "      <td>1.76<\/td>\n",
       "      <td>69.41<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>13<\/th>\n",
       "      <td>ravi<\/td>\n",
       "      <td>1.73<\/td>\n",
       "      <td>64.56<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>14<\/th>\n",
       "      <td>joe<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>65.45<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>15<\/th>\n",
       "      <td>jack<\/td>\n",
       "      <td>1.74<\/td>\n",
       "      <td>55.93<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>16<\/th>\n",
       "      <td>tom<\/td>\n",
       "      <td>1.77<\/td>\n",
       "      <td>64.18<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>17<\/th>\n",
       "      <td>tracy<\/td>\n",
       "      <td>1.78<\/td>\n",
       "      <td>61.90<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>18<\/th>\n",
       "      <td>john<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>50.97<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>19<\/th>\n",
       "      <td>jack<\/td>\n",
       "      <td>1.74<\/td>\n",
       "      <td>55.93<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>20<\/th>\n",
       "      <td>tom<\/td>\n",
       "      <td>1.77<\/td>\n",
       "      <td>64.18<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>21<\/th>\n",
       "      <td>tracy<\/td>\n",
       "      <td>1.78<\/td>\n",
       "      <td>61.90<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>22<\/th>\n",
       "      <td>john<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>50.97<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>23<\/th>\n",
       "      <td>jack<\/td>\n",
       "      <td>1.74<\/td>\n",
       "      <td>55.93<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>24<\/th>\n",
       "      <td>tom<\/td>\n",
       "      <td>1.77<\/td>\n",
       "      <td>64.18<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>25<\/th>\n",
       "      <td>tracy<\/td>\n",
       "      <td>1.78<\/td>\n",
       "      <td>61.90<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>26<\/th>\n",
       "      <td>john<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>50.97<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>27<\/th>\n",
       "      <td>simon<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>50.97<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>28<\/th>\n",
       "      <td>simon<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>50.97<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>29<\/th>\n",
       "      <td>simon<\/td>\n",
       "      <td>1.72<\/td>\n",
       "      <td>50.97<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"cbd8eAXJkU5b5kks6qKyjs",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Loading Data\n",
    "\n",
    "log(\"Loading Phase Started:\")\n",
    "load(targetfile, transformed_data)\n",
    "log(\"Loading Phase Ended:\")"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"nhBJQD33YCabcRT6QsNjaw",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "log(\"ETL Job Ended\")"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"uPwsBogzJ7l9Vin1PfjnDQ",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "**So this was the simple ETL implementation thats shows how data is extracted from a web source, transform into the usable format, and then loading the data (in this case, a csv file).**"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"sm5sdiCESI5rcH2IO0LU9Z",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **EXAMPLE:** 2"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"WYuEuUf7OhYe8Oh8ODAYDa",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **LET'S PERFORM ETL ON CAR DEALERSHIP DATA:**\n",
    "\n",
    "**ABOUT THE DATA:**\n",
    "\n",
    "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"uncdHyCtt0uaDEB7DKI6Vw",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Downloading the File:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"11UWv9GgWEXpaYaK7pHkqH",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!wget https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork\/labs\/module%206\/Lab%20-%20Extract%20Transform%20Load\/data\/datasource.zip"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "--2022-09-07 14:50:27--  https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork\/labs\/module%206\/Lab%20-%20Extract%20Transform%20Load\/data\/datasource.zip\r\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\r\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 4249 (4.1K) [application\/zip]\r\n",
      "Saving to: ‘datasource.zip’\r\n",
      "\r\n",
      "\rdatasource.zip        0%[                    ]       0  --.-KB\/s               \rdatasource.zip      100%[===================>]   4.15K  --.-KB\/s    in 0s      \r\n",
      "\r\n",
      "2022-09-07 14:50:27 (1.05 GB\/s) - ‘datasource.zip’ saved [4249\/4249]\r\n",
      "\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"lUtsU10Ps6jN4zskwNmRVX",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Unzip the Files:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"N0W5AwOQmnbuHESQPavre1",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!unzip datasource.zip -d dealership_data"
   ],
   "execution_count":null,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Archive:  datasource.zip\r\n",
      "  inflating: dealership_data\/used_car_prices1.csv  \r\n",
      "  inflating: dealership_data\/used_car_prices2.csv  \r\n",
      "  inflating: dealership_data\/used_car_prices3.csv  \r\n",
      "  inflating: dealership_data\/used_car_prices1.json  \r\n",
      "  inflating: dealership_data\/used_car_prices2.json  \r\n",
      "  inflating: dealership_data\/used_car_prices3.json  \r\n",
      "  inflating: dealership_data\/used_car_prices1.xml  \r\n",
      "  inflating: dealership_data\/used_car_prices2.xml  \r\n",
      "  inflating: dealership_data\/used_car_prices3.xml  \r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"HJ67Aot6o0Wlfph9oRMR3U",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Set Paths (Optional):"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"3wbe7hwTeD5MIbyM0U7tUv",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"VZwB5DTY4e3rZOFNMMa5dI",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Extract"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"aEV1U3GY4TqVuuiWm8iNe3",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# CSV Extract Function\n",
    "def extract_csv_data(file):\n",
    "    \"\"\"\n",
    "    Extracts the data from a CSV file and returns a dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "    return df"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"dGILgWYq4SC6oFRG5zsSaJ",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# JSON extract function\n",
    "def extract_json_data(file):\n",
    "    \"\"\"\n",
    "    Extracts the data from a JSON file and returns a dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.read_json(file, lines=True)\n",
    "    return df"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"KqoiIxn3stpF0NPOo8SKGs",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\n",
    "def extract_xml_data(file):\n",
    "    \"\"\"Extract data from XML file\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"car_model\", \"year_of_manufacture\", \"price\", \"fuel\"])\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    for i in root:\n",
    "        car_model = i.find(\"car_model\").text\n",
    "        year_of_manufacture = int(i.find(\"year_of_manufacture\").text)\n",
    "        price = i.find(\"price\").text\n",
    "        fuel = i.find(\"fuel\").text\n",
    "        # Now Append the extracted data to df\n",
    "        df = df.append({\"car_model\": car_model, \"year_of_manufacture\": year_of_manufacture, \"price\": price, \"fuel\": fuel}, ignore_index=True)\n",
    "        return df"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"CT8FRFXEGdGJ8FdnsoXblv",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# **Extract Function:**\n",
    "\n",
    "It will extract data from each file and append it to Pandas Dataframe:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"400ttZXbazdzTepH1rVfHD",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data\/*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_csv_data(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data\/*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_json_data(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data\/*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_xml_data(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"9vrWvadrr1mfGiRZgJbhqi",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Transform:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"BfhRhuFAgHFAWgRaKEq0BW",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def transform(data):\n",
    "    \"\"\" This function return data after applying transformation rules that need to be applied. \"\"\"\n",
    "    data.price = data.price.astype(float)\n",
    "    data['price'] = round(data.price, 2)\n",
    "    return data"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"fI8iFEaBaX7NFJieMUvaLn",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Loading:\n",
    "\n",
    "It will load the data in the required format:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"IjogiWnzNc2VUsL8Q5BDwo",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Load Function\n",
    "def load(targetfile, data_to_load):\n",
    "    data_to_load.to_csv(targetfile)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"UL0YNdgn2Y9l0yc1Tji9oX",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Logging:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"IVO4jHBdaoeVboIQCCFKXF",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Log function\n",
    "def log(message):\n",
    "    timestamp_format = '%H:%M:%S-%h-%d-%Y'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\", 'a') as f:\n",
    "        f.write(timestamp+ ', '+ message+ '\\n')"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"9ypBYRgxNE1RdpRgSmhqkT",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Running ETL Process:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"FYJgN3cNYTz61zn8Oqyz6C",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Log that you have started the ETL process\n",
    "log(\"ETL JOB STARTED:\")\n",
    "\n",
    "# Log that you have started the Extract step\n",
    "log(\"Extract Phase Started\")\n",
    "\n",
    "# Call the Extract function\n",
    "extracted_data = extract()\n",
    "# Log that you have completed the Extract step\n",
    "log(\"Extract Phase is Ended\")\n",
    "\n",
    "# Log that you have started the Transform step\n",
    "log(\"Transformation Phase is Started\")\n",
    "\n",
    "# Call the Transform function\n",
    "transformed_data = transform(extracted_data)\n",
    "# Log that you have completed the Transform step\n",
    "log(\"Transformation Phase is Ended\")\n",
    "\n",
    "# Log that you have started the Load step\n",
    "log(\"Loading Phase is Started\")\n",
    "# Call the Load function\n",
    "load(targetfile, transformed_data)\n",
    "# Log that you have completed the Load step\n",
    "log(\"Loading Phase is Ended\")\n",
    "\n",
    "# Log that you have completed the ETL process\n",
    "log(\"ETL JOB IS ENDED\")"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"PaPvR4Jm6v7ran9ZG99DrA",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Author:"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"BUQVs7qUo5zv031yGqK0tz",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Umer Farooq"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"zG5TkvZE44yt75wlz5mezK",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "version":1,
   "computation_mode":"REACTIVE",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}